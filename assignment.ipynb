{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/jun/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/jun/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import Counter\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform Raw texts into training and development data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dev = pd.read_csv('dev.tsv', sep='\\t')\n",
    "data_test = pd.read_csv('test.tsv', sep='\\t')\n",
    "data_train = pd.read_csv('train.tsv', sep='\\t')\n",
    "\n",
    "data_dev_phrases = list(data_dev['Phrase'])\n",
    "data_test_phrases = list(data_test['Phrase'])\n",
    "data_train_phrases = list(data_train['Phrase'])\n",
    "\n",
    "data_dev_sentiments_5 = list(data_dev['Sentiment'])\n",
    "data_train_sentiments_5 = list(data_train['Sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map to 3-value Sentiment Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_3_value(sentiments):\n",
    "    value_scale = {\n",
    "        0: 0,\n",
    "        1: 0,\n",
    "        2: 1,\n",
    "        3: 2,\n",
    "        4: 2,\n",
    "    }\n",
    "    \n",
    "    return np.array([value_scale[sentiment] for sentiment in sentiments])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, 1, 3, 1, 4, 1, 3, 1, 1, 1, 1, 4, 3, 3, 3, 3, 2, 1, 2]\n",
      "[0 2 0 2 0 2 0 2 0 0 0 0 2 2 2 2 2 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "data_dev_sentiments_3 = map_to_3_value(data_dev_sentiments_5)\n",
    "data_train_sentiments_3 = map_to_3_value(data_train_sentiments_5)\n",
    "\n",
    "print(data_train_sentiments_5[:20])\n",
    "print(data_train_sentiments_3[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Pre-Processing\n",
    "\n",
    "1. Tokenisation\n",
    "2. Remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_stop_words = {\n",
    "    'a', 'ad', 'after', 'again', 'all', 'also', 'am', 'an', 'and', 'any',\n",
    "    'are', 'as', 'at', 'be', 'because', 'been', 'being', 'between', 'both',\n",
    "    'but', 'by', 'can', 'could', 'does', 'each', 'ed', 'eg', 'either', 'etc',\n",
    "    'even', 'ever', 'every', 'for', 'from', 'had', 'has', 'have', 'he', 'her',\n",
    "    'hers', 'herself', 'him', 'himself', 'his', 'i', 'ie', 'if', 'in', 'inc',\n",
    "    'into', 'is', 'it', 'its', 'itself', 'li', 'll', 'ltd', 'may', 'maybe',\n",
    "    'me', 'might', 'mine', 'minute', 'minutes', 'must', 'my', 'myself',\n",
    "    'neither', 'nor', 'now', 'of', 'on', 'only', 'or', 'other', 'our', 'ours',\n",
    "    'ourselves', 'own', 'same', 'seem', 'seemed', 'shall', 'she', 'some',\n",
    "    'somehow', 'something', 'sometimes', 'somewhat', 'somewhere', 'spoiler',\n",
    "    'spoilers', 'such', 'suppose', 'that', 'the', 'their', 'theirs', 'them',\n",
    "    'themselves', 'there', 'these', 'they', 'this', 'those', 'thus', 'to',\n",
    "    'today', 'tomorrow', 'us', 've', 'vs', 'was', 'we', 'were', 'what',\n",
    "    'whatever', 'when', 'where', 'which', 'who', 'whom', 'whose', 'will',\n",
    "    'with', 'yesterday', 'you', 'your', 'yours', 'yourself', 'yourselves'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unigram extraction from a phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_unigrams(phrase):\n",
    "    return [\n",
    "        word.lower() for word in re.findall(r'\\b[A-Za-z]{2,}\\b', phrase)\n",
    "        if word.lower() not in default_stop_words\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a vocabulary of unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['horribly', 'forgotten', 'pepper', 'threefold', 'streaks', 'bullet', 'housing', 'nurtured', 'parts', 'diverges', 'childish', 'ratliff', 'bohos', 'acceptable', 'trumpet', 'discomfort', 'conquer', 'gamely', 'surveillance', 'vengefulness', 'reeses', 'serious', 'nancy', 'sinuously', 'giants', 'most', 'geriatric', 'frazzled', 'hearty', 'cosby', 'singh', 'intoxication', 'indistinct', 'limb', 'luscious', 'exposes', 'cyber', 'details', 'subliminally', 'violinist', 'bronze', 'perkiness', 'space', 'groen', 'develop', 'laundry', 'william', 'degree', 'reasonable', 'stolid']\n"
     ]
    }
   ],
   "source": [
    "vocab = { unigram for phrase in data_train_phrases \n",
    "         for unigram in extract_unigrams(phrase) }\n",
    "\n",
    "print(list(vocab)[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create vocabulary id -> word and word -> id dictionaries for reference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_id_to_word = dict(enumerate(vocab))\n",
    "\n",
    "word_to_vocab_id = {v: k for k, v in vocab_id_to_word.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract unigrams for each phrase in development, train, and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dev_unigrams = [extract_unigrams(phrase) for phrase in data_dev_phrases]\n",
    "\n",
    "data_train_unigrams = [extract_unigrams(phrase) for phrase in data_train_phrases]\n",
    "\n",
    "data_test_unigrams = [extract_unigrams(phrase) for phrase in data_test_phrases]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorise phrases\n",
    "\n",
    "Vectorise the dataset into an array with dimentionality $N \\times |vocab|$, where $N$ is the number of phrases and $|vocab|$ is the size of the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorise(data_unigrams, vocab):\n",
    "    vec = []\n",
    "    \n",
    "    for unigrams in data_unigrams:\n",
    "        counter = Counter(unigrams)\n",
    "        vec.append([counter[v] for v in vocab])\n",
    "    \n",
    "    return np.array(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dev_vec = vectorise(data_dev_unigrams, vocab)\n",
    "\n",
    "data_train_vec = vectorise(data_train_unigrams, vocab)\n",
    "\n",
    "data_test_vec = vectorise(data_test_unigrams, vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the prior probability of each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_prior_probability(sentiments):    \n",
    "    counter = Counter(sentiments)\n",
    "\n",
    "    return np.array([v for (_, v) in sorted(counter.items())]) / len(sentiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the probability of each word in vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_word_probability(total_vocab, data_unigrams, sentiments):\n",
    "    probs = np.zeros((total_vocab, len(set(sentiments))))\n",
    "    \n",
    "    for i, unigrams in enumerate(data_unigrams):\n",
    "        for word, count in Counter(unigrams).items():\n",
    "            probs[word_to_vocab_id[word]][sentiments[i]] += count\n",
    "\n",
    "    # With Laplace smoothing\n",
    "    return np.log10(probs[:] + 1) / (probs.sum(axis=0) + total_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3-value Sentiment scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.38331784 0.19577633 0.42090583] \n",
      "\n",
      "[[1.10654774e-05 0.00000000e+00 6.45502296e-06]\n",
      " [1.80470163e-05 1.07399478e-05 1.29100459e-05]\n",
      " [0.00000000e+00 1.07399478e-05 0.00000000e+00]\n",
      " ...\n",
      " [0.00000000e+00 0.00000000e+00 1.29100459e-05]\n",
      " [6.98153893e-06 0.00000000e+00 0.00000000e+00]\n",
      " [1.10654774e-05 1.07399478e-05 1.02309693e-05]]\n"
     ]
    }
   ],
   "source": [
    "data_train_3_prob = calculate_prior_probability(data_train_sentiments_3)\n",
    "word_prob_3 = calculate_word_probability(len(vocab), data_train_unigrams, data_train_sentiments_3)\n",
    "\n",
    "print(data_train_3_prob, '\\n')\n",
    "print(word_prob_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5-value Sentiment scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.12471776 0.25860008 0.19577633 0.27068668 0.15021915] \n",
      "\n",
      "[[2.04185927e-05 0.00000000e+00 0.00000000e+00 8.54010031e-06\n",
      "  0.00000000e+00]\n",
      " [1.28826976e-05 2.06942801e-05 1.07399478e-05 1.35357387e-05\n",
      "  1.18464443e-05]\n",
      " [0.00000000e+00 0.00000000e+00 1.07399478e-05 0.00000000e+00\n",
      "  0.00000000e+00]\n",
      " ...\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 8.54010031e-06\n",
      "  1.87761700e-05]\n",
      " [0.00000000e+00 8.91254132e-06 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00]\n",
      " [0.00000000e+00 1.41260438e-05 1.07399478e-05 8.54010031e-06\n",
      "  1.18464443e-05]]\n"
     ]
    }
   ],
   "source": [
    "data_train_5_prob = calculate_prior_probability(data_train_sentiments_5)\n",
    "word_prob_5 = calculate_word_probability(len(vocab), data_train_unigrams, data_train_sentiments_5)\n",
    "\n",
    "print(data_train_5_prob, '\\n')\n",
    "print(word_prob_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict development sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiments(prior_prob, word_prob, data_vec):\n",
    "    return np.argmax(data_vec.dot(prior_prob * word_prob), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3-value Sentiment scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[253,   0, 133],\n",
       "       [ 71,   0, 110],\n",
       "       [ 53,   0, 380]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_dev_sentiments_3 = predict_sentiments(data_train_3_prob, word_prob_3, data_dev_vec)\n",
    "\n",
    "confusion_matrix(data_dev_sentiments_3, pred_dev_sentiments_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5-value Sentiment scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1,  95,   2,  35,   0],\n",
       "       [  0, 171,   3,  79,   0],\n",
       "       [  1,  85,   4,  91,   0],\n",
       "       [  3,  65,   1, 214,   0],\n",
       "       [  0,  20,   0, 129,   1]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_dev_sentiments_5 = predict_sentiments(data_train_5_prob, word_prob_5, data_dev_vec)\n",
    "\n",
    "confusion_matrix(data_dev_sentiments_5, pred_dev_sentiments_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict test sentiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3-value Sentiment scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, ..., 2, 0, 0])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test_sentiments_3 = predict_sentiments(data_train_3_prob, word_prob_3, data_test_vec)\n",
    "\n",
    "pred_test_sentiments_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5-value Sentiment scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 1, ..., 3, 1, 1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test_sentiments_5 = predict_sentiments(data_train_5_prob, word_prob_5, data_test_vec)\n",
    "\n",
    "pred_test_sentiments_5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
